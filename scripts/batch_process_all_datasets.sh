#!/bin/bash

# é«˜æ•ˆæ‰¹é‡å¤„ç†æ‰€æœ‰æ•°æ®é›†çš„è„šæœ¬
# ç¡¬ä»¶é…ç½®: GPU 24GB, CPU 24æ ¸, å†…å­˜ 127GB
# æ•°æ®åº“: UniRef50 (çº¦37GB)

set -e

echo "ğŸš€ é«˜æ•ˆæ‰¹é‡å¤„ç†æ‰€æœ‰æ•°æ®é›†"
echo "================================"
echo "ç¡¬ä»¶é…ç½®:"
echo "  GPU: 24GB VRAM"
echo "  CPU: 24 cores"
echo "  å†…å­˜: 127GB"
echo "  æ•°æ®åº“: UniRef50 (~37GB)"
echo ""

# é…ç½®å‚æ•°
HOST_DATA_DIR="$(pwd)/data"  # å®¿ä¸»æœºæ•°æ®ç›®å½•
DOCKER_DATABASE="/data/mmseqs_db/production/UniRef50"  # Dockerå®¹å™¨å†…æ•°æ®åº“è·¯å¾„
DOCKER_OUTPUT_DIR="/data/real_msa"  # Dockerå®¹å™¨å†…è¾“å‡ºç›®å½•
HOST_OUTPUT_DIR="data/real_msa"  # å®¿ä¸»æœºè¾“å‡ºç›®å½•
THREADS=20  # ç•™4ä¸ªæ ¸å¿ƒç»™ç³»ç»Ÿ
GPU_ID=0
DB_INIT_TIMEOUT=600
SEARCH_TIMEOUT=1800  # 30åˆ†é’Ÿè¶…æ—¶

# æ ¹æ®æ•°æ®è§„æ¨¡ä¼˜åŒ–çš„batch-size
declare -A BATCH_SIZES=(
    ["Ec_complete_v2.jsonl"]=18780    # 18,780æ¡ - å¤§æ‰¹æ¬¡
    ["Human_complete_v2.jsonl"]=13421 # 13,421æ¡ - ä¸­å¤§æ‰¹æ¬¡
    ["mouse_complete_v2.jsonl"]=13253 # 13,253æ¡ - ä¸­å¤§æ‰¹æ¬¡
    ["Sac_complete_v2.jsonl"]=6384   # 6,384æ¡ - ä¸­æ‰¹æ¬¡
    ["Pic_complete_v2.jsonl"]=320    # 320æ¡ - å°æ‰¹æ¬¡
)

# æ•°æ®æ–‡ä»¶åˆ—è¡¨
DATA_FILES=(
    "Ec_complete_v2.jsonl"
    "Human_complete_v2.jsonl" 
    "mouse_complete_v2.jsonl"
    "Sac_complete_v2.jsonl"
    "Pic_complete_v2.jsonl"
)

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p "$HOST_OUTPUT_DIR"

# æ£€æŸ¥GPUçŠ¶æ€
echo "ğŸ” æ£€æŸ¥GPUçŠ¶æ€..."
if command -v nvidia-smi &> /dev/null; then
    nvidia-smi --query-gpu=name,memory.total,memory.used,memory.free --format=csv,noheader,nounits
    echo "âœ… GPUå¯ç”¨"
else
    echo "âš ï¸  nvidia-smiä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼"
fi

echo ""
echo "ğŸ“Š å¤„ç†è®¡åˆ’:"
for file in "${DATA_FILES[@]}"; do
    count=$(wc -l < "data/enhanced/$file")
    batch_size=${BATCH_SIZES[$file]}
    estimated_batches=$(( (count + batch_size - 1) / batch_size ))
    echo "  $file: $countæ¡è®°å½•, batch-size=$batch_size, é¢„è®¡$estimated_batchesä¸ªæ‰¹æ¬¡"
done

echo ""
echo "â° å¼€å§‹å¤„ç† (å¼€å§‹æ—¶é—´: $(date))"
echo "================================"

# æ€»ä½“ç»Ÿè®¡
TOTAL_START_TIME=$(date +%s)
TOTAL_PROCESSED=0
TOTAL_ERRORS=0

# å¤„ç†æ¯ä¸ªæ–‡ä»¶
for file in "${DATA_FILES[@]}"; do
    echo ""
    echo "ğŸ“ å¤„ç†æ–‡ä»¶: $file"
    echo "----------------------------------------"
    
    # æ–‡ä»¶çº§ç»Ÿè®¡
    FILE_START_TIME=$(date +%s)
    input_file="data/enhanced/$file"
    output_file="$HOST_OUTPUT_DIR/${file%.jsonl}_msa_features.jsonl"
    batch_size=${BATCH_SIZES[$file]}
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if [ ! -f "$input_file" ]; then
        echo "âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: $input_file"
        continue
    fi
    
    # è·å–è®°å½•æ•°
    total_records=$(wc -l < "$input_file")
    echo "ğŸ“Š è®°å½•æ•°: $total_records"
    echo "ğŸ“¦ æ‰¹æ¬¡å¤§å°: $batch_size"
    echo "ğŸ¯ è¾“å‡ºæ–‡ä»¶: $output_file"
    
    # è¿è¡Œå¤„ç†
    echo "ğŸƒ å¼€å§‹å¤„ç†..."
    docker run --rm \
        --gpus all \
        --entrypoint="" \
        -v "$HOST_DATA_DIR":/data \
        codon-verifier/msa-features-lite:latest \
        python3 app.py \
        --input "/data/enhanced/$file" \
        --output "/data/real_msa/${file%.jsonl}_msa_features.jsonl" \
        --use-mmseqs2 \
        --database "$DOCKER_DATABASE" \
        --use-gpu \
        --gpu-id $GPU_ID \
        --threads $THREADS \
        --batch-size $batch_size \
        --db-init-timeout $DB_INIT_TIMEOUT \
        --search-timeout $SEARCH_TIMEOUT \
        --log-level INFO
    
    # è®¡ç®—æ–‡ä»¶å¤„ç†æ—¶é—´
    FILE_END_TIME=$(date +%s)
    FILE_DURATION=$((FILE_END_TIME - FILE_START_TIME))
    FILE_HOURS=$((FILE_DURATION / 3600))
    FILE_MINUTES=$(((FILE_DURATION % 3600) / 60))
    FILE_SECONDS=$((FILE_DURATION % 60))
    
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
    if [ -f "$output_file" ]; then
        output_records=$(wc -l < "$output_file")
        echo "âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: $output_recordsæ¡è®°å½•"
        echo "â±ï¸  ç”¨æ—¶: ${FILE_HOURS}h ${FILE_MINUTES}m ${FILE_SECONDS}s"
        TOTAL_PROCESSED=$((TOTAL_PROCESSED + output_records))
    else
        echo "âŒ è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ: $output_file"
        TOTAL_ERRORS=$((TOTAL_ERRORS + 1))
    fi
    
    echo "----------------------------------------"
done

# æ€»ä½“ç»Ÿè®¡
TOTAL_END_TIME=$(date +%s)
TOTAL_DURATION=$((TOTAL_END_TIME - TOTAL_START_TIME))
TOTAL_HOURS=$((TOTAL_DURATION / 3600))
TOTAL_MINUTES=$(((TOTAL_DURATION % 3600) / 60))
TOTAL_SECONDS=$((TOTAL_DURATION % 60))

echo ""
echo "ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ!"
echo "================================"
echo "ğŸ“Š æ€»ä½“ç»Ÿè®¡:"
echo "  æ€»å¤„ç†æ—¶é—´: ${TOTAL_HOURS}h ${TOTAL_MINUTES}m ${TOTAL_SECONDS}s"
echo "  æˆåŠŸå¤„ç†è®°å½•: $TOTAL_PROCESSED"
echo "  é”™è¯¯æ–‡ä»¶æ•°: $TOTAL_ERRORS"
echo "  å¹³å‡å¤„ç†é€Ÿåº¦: $((TOTAL_PROCESSED / (TOTAL_DURATION / 60))) è®°å½•/åˆ†é’Ÿ"

echo ""
echo "ğŸ“ è¾“å‡ºæ–‡ä»¶:"
for file in "${DATA_FILES[@]}"; do
    output_file="$HOST_OUTPUT_DIR/${file%.jsonl}_msa_features.jsonl"
    if [ -f "$output_file" ]; then
        size=$(du -h "$output_file" | cut -f1)
        records=$(wc -l < "$output_file")
        echo "  âœ… $output_file ($recordsæ¡è®°å½•, $size)"
    else
        echo "  âŒ $output_file (æœªç”Ÿæˆ)"
    fi
done

echo ""
echo "ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:"
echo "  - ä½¿ç”¨GPUåŠ é€Ÿ (24GB VRAM)"
echo "  - ä¼˜åŒ–æ‰¹æ¬¡å¤§å° (æ ¹æ®æ•°æ®è§„æ¨¡)"
echo "  - å¹¶è¡Œå¤„ç† (20ä¸ªCPUæ ¸å¿ƒ)"
echo "  - å¤§æ•°æ®åº“ç¼“å­˜ (37GB UniRef50)"
echo "  - åˆç†è¶…æ—¶è®¾ç½® (30åˆ†é’Ÿæœç´¢è¶…æ—¶)"

echo ""
echo "ğŸ” è´¨é‡æ£€æŸ¥:"
if [ -f "$HOST_OUTPUT_DIR/Ec_complete_v2_msa_features.jsonl" ]; then
    echo "  æ£€æŸ¥Ecæ•°æ®é›†ç»“æœè´¨é‡..."
    head -1 "$HOST_OUTPUT_DIR/Ec_complete_v2_msa_features.jsonl" | python3 -c "
import json, sys
try:
    data = json.loads(sys.stdin.read())
    msa = data.get('msa_features', {})
    print(f'    MSAæ·±åº¦: {msa.get(\"msa_depth\", \"N/A\")}')
    print(f'    MSAè¦†ç›–åº¦: {msa.get(\"msa_coverage\", \"N/A\")}')
    print(f'    ä¿å®ˆæ€§: {msa.get(\"conservation_mean\", \"N/A\")}')
    print(f'    å…±è¿›åŒ–åˆ†æ•°: {msa.get(\"coevolution_score\", \"N/A\")}')
except Exception as e:
    print(f'    è§£æé”™è¯¯: {e}')
"
fi

echo ""
echo "âœ… æ‰¹é‡å¤„ç†å®Œæˆ! (ç»“æŸæ—¶é—´: $(date))"
